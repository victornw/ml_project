{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "tmqrN1HZlsRz"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>Email Text</th>\n",
              "      <th>Email Type</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>re : 6 . 1100 , disc : uniformitarianism , re ...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>the other side of * galicismos * * galicismo *...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>re : equistar deal tickets are you still avail...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>\\nHello I am your hot lil horny toy.\\n    I am...</td>\n",
              "      <td>Phishing Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>software at incredibly low prices ( 86 % lower...</td>\n",
              "      <td>Phishing Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18645</th>\n",
              "      <td>18646</td>\n",
              "      <td>date a lonely housewife always wanted to date ...</td>\n",
              "      <td>Phishing Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18646</th>\n",
              "      <td>18647</td>\n",
              "      <td>request submitted : access request for anita ....</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18647</th>\n",
              "      <td>18648</td>\n",
              "      <td>re : important - prc mtg hi dorn &amp; john , as y...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18648</th>\n",
              "      <td>18649</td>\n",
              "      <td>press clippings - letter on californian utilit...</td>\n",
              "      <td>Safe Email</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18649</th>\n",
              "      <td>18650</td>\n",
              "      <td>empty</td>\n",
              "      <td>Phishing Email</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>18650 rows × 3 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "       Unnamed: 0                                         Email Text  \\\n",
              "0               0  re : 6 . 1100 , disc : uniformitarianism , re ...   \n",
              "1               1  the other side of * galicismos * * galicismo *...   \n",
              "2               2  re : equistar deal tickets are you still avail...   \n",
              "3               3  \\nHello I am your hot lil horny toy.\\n    I am...   \n",
              "4               4  software at incredibly low prices ( 86 % lower...   \n",
              "...           ...                                                ...   \n",
              "18645       18646  date a lonely housewife always wanted to date ...   \n",
              "18646       18647  request submitted : access request for anita ....   \n",
              "18647       18648  re : important - prc mtg hi dorn & john , as y...   \n",
              "18648       18649  press clippings - letter on californian utilit...   \n",
              "18649       18650                                              empty   \n",
              "\n",
              "           Email Type  \n",
              "0          Safe Email  \n",
              "1          Safe Email  \n",
              "2          Safe Email  \n",
              "3      Phishing Email  \n",
              "4      Phishing Email  \n",
              "...               ...  \n",
              "18645  Phishing Email  \n",
              "18646      Safe Email  \n",
              "18647      Safe Email  \n",
              "18648      Safe Email  \n",
              "18649  Phishing Email  \n",
              "\n",
              "[18650 rows x 3 columns]"
            ]
          },
          "execution_count": 1,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "df = pd.read_csv(\"Phishing_Email.csv\", encoding='latin-1')\n",
        "\n",
        "df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "paoGwy3emXrP"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Email Type\n",
            "Safe Email        11322\n",
            "Phishing Email     7328\n",
            "Name: count, dtype: int64\n",
            "Total:  18650\n"
          ]
        }
      ],
      "source": [
        "df = df.drop(columns=[\"Unnamed: 0\"])\n",
        "df = df.rename(columns={\"Email Text\": \"texto\"})\n",
        "print(df[\"Email Type\"].value_counts())\n",
        "print(\"Total: \", df[\"Email Type\"].value_counts().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JVBj7x1e5sUr",
        "outputId": "d7ec091b-df11-42a8-bec7-bcffc6abbea4"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "C:\\Users\\Samuel\\AppData\\Local\\Temp\\ipykernel_9528\\1425109582.py:1: FutureWarning: A value is trying to be set on a copy of a DataFrame or Series through chained assignment using an inplace method.\n",
            "The behavior will change in pandas 3.0. This inplace method will never work because the intermediate object on which we are setting values always behaves as a copy.\n",
            "\n",
            "For example, when doing 'df[col].method(value, inplace=True)', try using 'df.method({col: value}, inplace=True)' or df[col] = df[col].method(value) instead, to perform the operation inplace on the original object.\n",
            "\n",
            "\n",
            "  df[\"texto\"].replace('empty',np.nan,inplace=True)\n"
          ]
        }
      ],
      "source": [
        "df[\"texto\"].replace('empty',np.nan,inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3KDHLu3mnfOc",
        "outputId": "38ee9b56-cae9-4fcc-c16b-ad1970660dc5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "18101\n"
          ]
        }
      ],
      "source": [
        "df = df.dropna()\n",
        "print(df.value_counts().sum())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "W3pyhoqXnh1Y"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "le = LabelEncoder()\n",
        "\n",
        "df[\"Email Type\"] = le.fit_transform(df[\"Email Type\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f_bXmB00nkWR",
        "outputId": "d9a1fb9a-05eb-4591-8a84-e87b0bd3c1e6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "                                               texto  Email Type\n",
            "0  6 1100 disc uniformitarianism 1086 sex lang di...           1\n",
            "1  galicismos galicismo spanish term names improp...           1\n",
            "2  equistar deal tickets available assist robert ...           1\n",
            "3  hello hot lil horny toy dream open minded pers...           0\n",
            "4  software incredibly low prices 86 lower draper...           0\n"
          ]
        }
      ],
      "source": [
        "import unicodedata\n",
        "import re\n",
        "from sklearn.feature_extraction.text import ENGLISH_STOP_WORDS\n",
        "\n",
        "def remove_accents(input_str):\n",
        "    nfkd_form = unicodedata.normalize('NFKD', input_str)\n",
        "    return ''.join([c for c in nfkd_form if not unicodedata.category(c) == 'Mn'])\n",
        "\n",
        "def remove_stopwords(text):\n",
        "    words = text.split()\n",
        "    return \" \".join([word for word in words if word not in ENGLISH_STOP_WORDS])\n",
        "\n",
        "def preprocess_text(text):\n",
        "    if pd.isna(text):\n",
        "        return \"\"\n",
        "    text = text.lower()\n",
        "    text = re.sub(r'https?://\\S+', '', text)\n",
        "    text = re.sub(r'[^a-zA-Z0-9\\s]', '', text)\n",
        "    text = re.sub(r'\\s+', ' ', text)\n",
        "    text = remove_accents(text)\n",
        "    text = remove_stopwords(text)\n",
        "    return text.strip()\n",
        "\n",
        "df[\"texto\"] = df[\"texto\"].apply(preprocess_text)\n",
        "\n",
        "print(df.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oQsvIssUn-31",
        "outputId": "9c427c02-ad12-4d02-887a-be813201d28b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "      w2v_0     w2v_1     w2v_2     w2v_3     w2v_4     w2v_5     w2v_6  \\\n",
            "0  0.153812 -0.061595 -0.118919  0.169105  0.358679 -0.100350 -0.054256   \n",
            "1 -0.006515 -0.050960 -0.070281  0.185318  0.282403 -0.066567  0.101860   \n",
            "2  0.114173 -0.171148 -0.259708  0.305689  0.367572  0.176437 -0.158071   \n",
            "3  0.095020 -0.041170 -0.151057  0.230449  0.314425 -0.125564 -0.175882   \n",
            "4  0.137910 -0.093879 -0.137078  0.099013  0.292562 -0.084732 -0.102193   \n",
            "\n",
            "      w2v_7     w2v_8     w2v_9  ...   w2v_191   w2v_192   w2v_193   w2v_194  \\\n",
            "0  0.397640 -0.031036  0.072123  ... -0.262040  0.041747 -0.169848  0.055648   \n",
            "1  0.338936 -0.093375  0.109206  ... -0.170371 -0.095704 -0.144121  0.068030   \n",
            "2  0.441043  0.059579  0.590908  ... -0.283245  0.103755 -0.222808  0.395738   \n",
            "3  0.313436  0.010741  0.338988  ... -0.193292  0.094837 -0.250937  0.043706   \n",
            "4  0.467764 -0.032607  0.178662  ... -0.246156  0.001393 -0.153404  0.148858   \n",
            "\n",
            "    w2v_195   w2v_196   w2v_197   w2v_198   w2v_199  Email Type  \n",
            "0  0.043062  0.179868 -0.266347 -0.103316  0.023813           1  \n",
            "1  0.039967  0.034305 -0.122326 -0.183916  0.069396           1  \n",
            "2  0.035553  0.218888 -0.252335 -0.166527 -0.244727           1  \n",
            "3  0.005763 -0.024016 -0.255020  0.127384  0.023893           0  \n",
            "4  0.058246  0.040641 -0.176391 -0.037235  0.035915           0  \n",
            "\n",
            "[5 rows x 201 columns]\n"
          ]
        }
      ],
      "source": [
        "from gensim.models import Word2Vec\n",
        "\n",
        "def word2vec(textos_tokenizados, vector_size=200, window=6, min_count=2):\n",
        "    model = Word2Vec(\n",
        "        sentences=textos_tokenizados,\n",
        "        vector_size=vector_size,\n",
        "        window=window,\n",
        "        min_count=min_count,\n",
        "        sg=1,\n",
        "        workers=4\n",
        "    )\n",
        "    return model\n",
        "\n",
        "def vetor_medio(texto, model):\n",
        "    palavras = texto.split()\n",
        "    vetores = [model.wv[p] for p in palavras if p in model.wv]\n",
        "    if vetores:\n",
        "        return np.mean(vetores, axis=0)\n",
        "    else:\n",
        "        return np.zeros(model.vector_size)\n",
        "\n",
        "def word2vec_transform(df, model):\n",
        "    vetores = df[\"texto\"].apply(lambda x: vetor_medio(x, model))\n",
        "    matriz = np.vstack(vetores.values)\n",
        "\n",
        "    df_w2v = pd.DataFrame(matriz, columns=[f\"w2v_{i}\" for i in range(model.vector_size)])\n",
        "    df_w2v[\"Email Type\"] = df[\"Email Type\"].values\n",
        "\n",
        "    return df_w2v, model\n",
        "\n",
        "df[\"tokens\"] = df[\"texto\"].apply(lambda x: x.lower().split())\n",
        "\n",
        "modelo_w2v = word2vec(df[\"tokens\"].tolist())\n",
        "\n",
        "df_final, modelo_w2v = word2vec_transform(df, modelo_w2v)\n",
        "\n",
        "print(df_final.head())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "oYr4642Zp14T",
        "outputId": "98ee352f-aae6-468d-d85c-0cca2f03fe66"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Fitting 3 folds for each of 400 candidates, totalling 1200 fits\n",
            "Best Params: {'ccp_alpha': 0.0, 'max_depth': 10, 'min_samples_leaf': 10, 'min_samples_split': 15}\n",
            "Best Score: 0.92866036817525\n",
            "Accuracy on Test Set: 0.9328914664457332\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.91      0.91      0.91      1381\n",
            "           1       0.95      0.94      0.95      2240\n",
            "\n",
            "    accuracy                           0.93      3621\n",
            "   macro avg       0.93      0.93      0.93      3621\n",
            "weighted avg       0.93      0.93      0.93      3621\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "\n",
        "\n",
        "X = df_final.drop(columns=[\"Email Type\"])\n",
        "y = df_final[\"Email Type\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=777)\n",
        "\n",
        "params = {\n",
        "    'max_depth': [10, 15],\n",
        "    'min_samples_split': [15, 20],\n",
        "    'min_samples_leaf': [5, 10],\n",
        "    'ccp_alpha': np.linspace(0, 0.1)\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(\n",
        "    DecisionTreeClassifier(random_state=77),\n",
        "    param_grid=params,\n",
        "    scoring='accuracy',\n",
        "    cv=3,\n",
        "    n_jobs=-1,\n",
        "    verbose=1\n",
        ")\n",
        "\n",
        "grid.fit(X_train, y_train)\n",
        "\n",
        "print(\"Best Params:\", grid.best_params_)\n",
        "print(\"Best Score:\", grid.best_score_)\n",
        "\n",
        "y_pred = grid.best_estimator_.predict(X_test)\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK9tedsKrOsi",
        "outputId": "78733323-a2e2-491e-bf2d-5da73bcf1f9d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Classe prevista: Phishing\n"
          ]
        }
      ],
      "source": [
        "novo_email = {\n",
        "    \"texto\": \"\"\"\n",
        "Subject: Your Account Has Been Flagged for Security Verification\n",
        "\n",
        "Dear User,\n",
        "\n",
        "We have noticed suspicious sign-in attempts to your Microsoft account. For your protection, please verify your identity by clicking the secure link below:\n",
        "\n",
        "[Secure Your Account]\n",
        "\n",
        "Failure to verify within 12 hours will result in account restriction.\n",
        "\n",
        "Microsoft Security Team\n",
        " \"\"\"\n",
        "}\n",
        "\n",
        "df_novo = pd.DataFrame([novo_email])\n",
        "\n",
        "df_novo[\"texto\"] = df_novo[\"texto\"].apply(lambda x: x.lower().split())\n",
        "\n",
        "X_novo = np.array([vetor_medio(\" \".join(df_novo[\"texto\"].iloc[0]), modelo_w2v)])\n",
        "\n",
        "X_novo_df = pd.DataFrame(X_novo, columns=[f\"w2v_{i}\" for i in range(X_novo.shape[1])])\n",
        "\n",
        "\n",
        "# Predição do modelo\n",
        "y_pred_novo = grid.best_estimator_.predict(X_novo_df)\n",
        "if y_pred_novo[0] == 0:\n",
        "  print(\"Classe prevista: Phishing\")\n",
        "else:\n",
        "  print(\"Classe prevista: Não Phishing\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "CbbsY7c-O9nV",
        "outputId": "f6c815e2-365b-463f-c7fd-f857b53a128a"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\Samuel\\Desktop\\ML-PLN\\ml_project\\venv\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_2\"</span>\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1mModel: \"sequential_2\"\u001b[0m\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             │         <span style=\"color: #00af00; text-decoration-color: #00af00\">6,432</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16</span>)             │           <span style=\"color: #00af00; text-decoration-color: #00af00\">528</span> │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)              │            <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span> │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
              "</pre>\n"
            ],
            "text/plain": [
              "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
              "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
              "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
              "│ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             │         \u001b[38;5;34m6,432\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_7 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16\u001b[0m)             │           \u001b[38;5;34m528\u001b[0m │\n",
              "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
              "│ dense_8 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m)              │            \u001b[38;5;34m17\u001b[0m │\n",
              "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,977</span> (27.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m6,977\u001b[0m (27.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">6,977</span> (27.25 KB)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m6,977\u001b[0m (27.25 KB)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "data": {
            "text/html": [
              "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> (0.00 B)\n",
              "</pre>\n"
            ],
            "text/plain": [
              "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m0\u001b[0m (0.00 B)\n"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "None\n",
            "Epoch 1/5\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 6ms/step - accuracy: 0.8714 - loss: 0.2852 - val_accuracy: 0.9582 - val_loss: 0.1069\n",
            "Epoch 2/5\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9662 - loss: 0.1039 - val_accuracy: 0.9568 - val_loss: 0.1184\n",
            "Epoch 3/5\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9717 - loss: 0.0870 - val_accuracy: 0.9675 - val_loss: 0.0824\n",
            "Epoch 4/5\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9776 - loss: 0.0647 - val_accuracy: 0.9696 - val_loss: 0.0771\n",
            "Epoch 5/5\n",
            "\u001b[1m91/91\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 4ms/step - accuracy: 0.9778 - loss: 0.0661 - val_accuracy: 0.9658 - val_loss: 0.0862\n",
            "\u001b[1m114/114\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step\n",
            "Accuracy on Test Set: 0.9726594863297432\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.97      0.95      0.96      1381\n",
            "           1       0.97      0.98      0.98      2240\n",
            "\n",
            "    accuracy                           0.97      3621\n",
            "   macro avg       0.97      0.97      0.97      3621\n",
            "weighted avg       0.97      0.97      0.97      3621\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras import optimizers\n",
        "from keras import regularizers\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import accuracy_score, classification_report\n",
        "\n",
        "\n",
        "X = df_final.drop(columns=[\"Email Type\"])\n",
        "y = df_final[\"Email Type\"]\n",
        "\n",
        "label_encoder = LabelEncoder()\n",
        "y_encoded = label_encoder.fit_transform(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=777)\n",
        "\n",
        "input_dim = X_train.shape[1]\n",
        "\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=input_dim, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(16, activation='relu', kernel_initializer='he_normal'))\n",
        "model.add(Dense(1, activation='sigmoid'))  # Output binário (Phishing ou Não)\n",
        "\n",
        "optimizer = optimizers.Adam(learning_rate=0.01)\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n",
        "\n",
        "print(model.summary())\n",
        "\n",
        "history = model.fit(X_train, y_train, epochs=5, batch_size=128, validation_split=0.2, verbose=1)\n",
        "\n",
        "y_pred_prob = model.predict(X_test)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int).flatten()\n",
        "\n",
        "print(\"Accuracy on Test Set:\", accuracy_score(y_test, y_pred))\n",
        "print(classification_report(y_test, y_pred, target_names=[str(c) for c in label_encoder.classes_]))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1ak5gruISjnd",
        "outputId": "6b3e1f91-343e-492c-abd2-f14c68a253b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step\n",
            "Classe prevista: Phishing\n",
            "Probabilidade de ser Não Phishing: 0.02271071\n",
            "Probabilidade de ser Phishing: 0.9772892892360687\n"
          ]
        }
      ],
      "source": [
        "novo_email = {\n",
        "    \"texto\": \"\"\" Action Required: Delivery Held Due to Unpaid Fee\n",
        "\n",
        "Hello,\n",
        "\n",
        "Your package is being held due to an unpaid delivery fee. To release your shipment, please complete the payment at the link below:\n",
        "\n",
        "[Complete Payment]\n",
        "\n",
        "Failure to act will result in return to sender.\n",
        "\n",
        "Thank you,  \n",
        "Fast Delivery Logistics\n",
        "    \"\"\"\n",
        "}\n",
        "\n",
        "df_novo = pd.DataFrame([novo_email])\n",
        "\n",
        "df_novo[\"texto\"] = df_novo[\"texto\"].apply(preprocess_text)\n",
        "\n",
        "# transformação w2c\n",
        "vetor_novo = vetor_medio(df_novo[\"texto\"].iloc[0], modelo_w2v)  \n",
        "X_novo = np.array([vetor_novo])  \n",
        "\n",
        "y_pred_prob = model.predict(X_novo)\n",
        "y_pred = (y_pred_prob > 0.5).astype(int) \n",
        "\n",
        "if y_pred[0][0] == 0:\n",
        "    print(\"Classe prevista: Phishing\")\n",
        "else:\n",
        "    print(\"Classe prevista: Não Phishing\")\n",
        "\n",
        "print(\"Probabilidade de ser Não Phishing:\", y_pred_prob[0][0])\n",
        "print(\"Probabilidade de ser Phishing:\", 1 - y_pred_prob[0][0])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {},
      "outputs": [],
      "source": [
        "# k-fold + gridsearchcv\n",
        "from sklearn.model_selection import KFold, cross_val_score\n"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
